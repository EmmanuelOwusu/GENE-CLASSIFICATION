{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvxopt in /home/aims/anaconda3/lib/python3.7/site-packages (1.2.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/aims/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip  install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the data \n",
    "X_train = pd.read_csv(\"Xtr.csv\")\n",
    "Y_train = pd.read_csv(\"Ytr.csv\")\n",
    "X_test = pd.read_csv(\"Xte.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the first 5 lines from the data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spectrum Method to encode the data, by define spectrum function\n",
    "def spectrum (DNA, k):\n",
    "    return [DNA[x:x+k].lower() for x in range(len(DNA)-k+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do one hot encoder for the sequence data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def on_hot(data):\n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "    data = onehot_encoder.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we choose k=5\n",
    "def spectrum_on_data(data,k=5):\n",
    "    data = data\n",
    "    d = 101 - k +1\n",
    "    outs = []\n",
    "    cols = ['word'+str(i) for i in range(d)]\n",
    "    for ind in range(len(data)):\n",
    "        seq = data.iloc[ind]['seq']\n",
    "        seq = spectrum(seq,k)\n",
    "        outs.append(seq)\n",
    "    outs_df = pd.DataFrame(data = outs,columns=cols)\n",
    "    outs_one_hot = on_hot(np.array(outs))\n",
    "    return outs_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine x train with x test data into one train set\n",
    "train_test = [X_train,X_test]\n",
    "train_test = pd.concat(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_onehot = spectrum_on_data(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test \n",
    "x_train = train_test_onehot[:2000,:]\n",
    "x_test = train_test_onehot[2000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop double index\n",
    "y = Y_train.drop(['Id'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first row\n",
    "y = y['Bound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y to numpy array\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 0 class in y to -1\n",
    "y_svm = y\n",
    "for i in range(len(y_svm)):\n",
    "    if y_svm[i] ==  0:y_svm[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split( x_train, y, test_size=0.15, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cvxopt to solve convex optimization problems\n",
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some kernels:\n",
    "\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "\n",
    "def  Exponential_Kernel(x, y, sigma=5):\n",
    "\n",
    "    return np.exp(-linalg.norm(x-y) / (2 * (sigma ** 2)))\n",
    "\n",
    "def quadratic_kernel(X1, X2):\n",
    "\n",
    "    return (1 + linear_kernel(X1, X2))**2\n",
    "\n",
    "def  Laplacian_Kernel(x, y, sigma=10.0):\n",
    "\n",
    "    return np.exp(-linalg.norm(x-y) / (sigma ))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(x, y, p=5):\n",
    "    return (1 + np.dot(x, y.T)) ** p\n",
    "# =rbf\n",
    "def gaussian_kernel(x, y, sigma=10):\n",
    "    return np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10.0):\n",
    "\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM CLASS\n",
    "\n",
    "class SVM(object):\n",
    "\n",
    "    def __init__(self, kernel=gaussian_kernel, C=20):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        # define gram matrix\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i,j] = self.kernel(X[i], X[j])\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = y.reshape(1,n_samples)\n",
    "        \n",
    "        A = A.astype('float')\n",
    "        A = cvxopt.matrix(A)\n",
    "        \n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "\n",
    "        # solve Quadratic Programing problem\n",
    "        print('P',P.size,'q',q.size,'G',G.size,'h',h.size,'A',A.size,'b',b.size)\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "\n",
    "        sv = a > 1e-12\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            print(len(self.a))\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])\n",
    "            \n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == linear_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else:\n",
    "            self.w = None\n",
    "\n",
    "    def project(self, X):\n",
    "        if self.w is not None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * self.kernel(X[i], sv)\n",
    "                y_predict[i] = s\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance from svm class\n",
    "svm_model = SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "svm_model.fit(X_train_,y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on splitted test data\n",
    "ypredict = svm_model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.6533333333333333\n"
     ]
    }
   ],
   "source": [
    "# calculate the model accuracy\n",
    "accuracy = np.mean(ypredict == y_test_)\n",
    "print('Accuracy is ' ,accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test data\n",
    "pred = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate the model performance we can validate it using k_fold cross validation\n",
    "\n",
    "import random\n",
    "\n",
    "class k_fold_cross_validation():\n",
    "    def __init__(self,model, k=5):\n",
    "        self.k = k\n",
    "        self.model = model\n",
    "        \n",
    "    def split_(self, X, y, i, l):\n",
    "\n",
    "        n = len(X)//self.k\n",
    "        validation_indices = l[i*n:(i+1)*n]\n",
    "        training_indices = [x  for x in l if x not in validation_indices]\n",
    "        \n",
    "        validation_set = X[validation_indices]\n",
    "        training_set = X[training_indices]\n",
    "        validation_target = y[validation_indices]\n",
    "        training_target = y[training_indices]\n",
    "        return training_set, validation_set, training_target, validation_target\n",
    "    \n",
    "    def validate(self, X, y):\n",
    "        l  = [j for j in range(len(X))]\n",
    "        random.shuffle(l)\n",
    "        accs = []\n",
    "        for i in range(self.k): \n",
    "            X_train, X_test, y_train, y_test = self.split_(X,y,i,l)\n",
    "            self.model.fit(X_train, y_train)\n",
    "            prediction = self.model.predict(X_test)\n",
    "            acc = np.mean(prediction==y_test)\n",
    "            accs.append(acc)\n",
    "            print(\"acc {} : {}\".format(i,acc))\n",
    "        average_loss = sum(accs)/len(accs)\n",
    "        print(\"accuracy loss: {}\".format(average_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the model you want to validate\n",
    "\n",
    "kfcv=k_fold_cross_validation(svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit whole data into the k_fold cross validation class\n",
    "kfcv.validate(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in test data\n",
    "pred = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert  y to 0 and 1 class\n",
    "# output = []\n",
    "# for i in range(len(pred)):\n",
    "#     if pred[i]==-1: \n",
    "#         pred[i]==0\n",
    "#         output.append(0)\n",
    "#     else:output.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output  = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # put the output in the form of dictionary and then data frames\n",
    "# Id = np.array([i for i in range(len(output))])\n",
    "# sub = {'Id':Id,'Bound':output}\n",
    "# submision = pd.DataFrame(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submision.to_csv('KRR_P5_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel\n",
    " \n",
    "    }\n",
    "    def __init__(self, kernel='polynomial', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf':\n",
    "            params['sigma'] = kwargs.get('sigma', 1)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['p'] = kwargs.get('p', 2)\n",
    "        #if self.kernel_name == 'Laplacian_Kernel':\n",
    "         #     params['sigma'] = kwargs.get('sigma', 1)\n",
    "        #     params['parameter_2'] = kwargs.get('parameter_2', None)\n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "\n",
    "    def __init__(self, lambd=0.00001, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y,  sample_weights=None):\n",
    "        n=X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X, X, **self.kernel_parameters) \n",
    "        \n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)] ,n*self.lambd)\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train,**self.kernel_parameters )\n",
    "        return  np.sign(K_x.dot(self.alpha))\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)    \n",
    "          \n",
    "    def Accuracy_check(self,X,y):\n",
    "        return np.mean(self.predict(X)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KernelRidgeRegression at 0x7f28bf394350>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance from the class and fit the data\n",
    "KR = KernelRidgeRegression(p=5)\n",
    "KR.fit(X_train_,y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = KR.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266666666666667"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = KR.Accuracy_check(X_test_,y_test_)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfc=k_fold_cross_validation(KR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfc.validate(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = KR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, lr=0.3, num_iter=100000, batch_size=1000, verbose=True):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        if (x>0).any():\n",
    "            return 1 / (1 + np.exp(-x))               \n",
    "        else:\n",
    "            return np.exp(x) / (1 + np.exp(x)) \n",
    "    \n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y = self.trans_y(y)\n",
    "        \n",
    "        X = self.__add_intercept(X)\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.sigmoid(z)\n",
    "            rand = np.random.choice(y.size, self.batch_size).squeeze()\n",
    "       \n",
    "            gradient = np.dot(X[rand].T, (h[rand].reshape(-1,1) - y[rand].reshape(-1,1)))/y.size   \n",
    "            self.theta =  self.theta.reshape(-1,1)\n",
    "            self.theta -= (self.lr * gradient)\n",
    "           \n",
    "            \n",
    "            if(self.verbose == True and i % 10000 == 0):\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.sigmoid(z)\n",
    "                print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "    def predict_probability(self, X):\n",
    "        X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "          return np.where(self.predict_probability(X) >= 0.5, 1, -1)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X,y):\n",
    "        return np.mean(self.predict(X)==y)\n",
    "    \n",
    "    def trans_y(self, y):\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(y, list):\n",
    "            y = np.array(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train_,np.array(y_train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = LR.Accuracy_check(X_test_,y_test_)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "kfcLR=k_fold_cross_validation(LR)\n",
    "kfcLR.validate(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedKernelRidgeRegression(KernelRidgeRegression):\n",
    "\n",
    "    def fit(self, K, y, sample_weights=None):\n",
    "\n",
    "        self.y_train = y\n",
    "        n = len(self.y_train)\n",
    "        \n",
    "        w = np.ones_like(self.y_train) if sample_weights is None else sample_weights\n",
    "        W = np.diag(np.sqrt(w))\n",
    "        \n",
    "        A = W.dot(K).dot(W)\n",
    "        A[np.diag_indices_from(A)] += self.lambd * n\n",
    "        self.alpha = W.dot(np.linalg.solve(A , W.dot(self.y_train)))\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class KernelLogisticRegression(KernelMethodBase):\n",
    "    def __init__(self, lambd=0.04, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        super().__init__(**kwargs)\n",
    "        #super(KernelLogisticRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, max_iter=100, tol=0.00001):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        K = self.kernel_function_(X, X, **self.kernel_parameters)\n",
    "        \n",
    "        # IRLS\n",
    "        KRR = KernelRidgeRegression(\n",
    "            lambd=2*self.lambd,\n",
    "            kernel=self.kernel_name,\n",
    "            **self.kernel_parameters\n",
    "        )\n",
    "    \n",
    "    # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "\n",
    "        for n_iter in range(max_iter):\n",
    "            alpha_old = alpha\n",
    "            m = K.dot(alpha_old)\n",
    "            w = sigmoid(m) * sigmoid(-m)\n",
    "            z = m + self.y_train / sigmoid(self.y_train * m)\n",
    "            alpha = KRR.fit(self.X_train, z, sample_weights=w).alpha\n",
    "\n",
    "            if np.sum((alpha-alpha_old)**2) < tol:\n",
    "                break\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X_test):\n",
    "        K_x = self.kernel_function_(X_test, self.X_train, **self.kernel_parameters)\n",
    "\n",
    "        return sigmoid(K_x.dot(self.alpha))\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas = self.decision_function(X)\n",
    "        predicted_classes = np.where(probas < 0.5, -1, 1)\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr=KernelLogisticRegression(lambd=0.0001, kernel='rbf', sigma=8.0, degree=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KernelLogisticRegression at 0x7f28bfed78d0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlr.fit(X_train_,y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=rlr.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.mean(pred==y_test_)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rlr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0 : 0.67\n",
      "acc 1 : 0.6125\n",
      "acc 2 : 0.68\n",
      "acc 3 : 0.6725\n",
      "acc 4 : 0.68\n",
      "accuracy loss: 0.663\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "kfcv=k_fold_cross_validation(rlr)\n",
    "kfcv.validate(x_train, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if (x>0).any():\n",
    "        return 1 / (1 + np.exp(-x))               \n",
    "    else:\n",
    "        return np.exp(x) / (1 + np.exp(x)) \n",
    "\n",
    "class KernelLogisticRegression(KernelMethodBase):\n",
    "\n",
    "    def __init__(self, lambd=0.000001, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        super().__init__(**kwargs)\n",
    "        #super(KernelLogisticRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, max_iter=100000, tol=0.0001):\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        K = self.kernel_function_(X, X, **self.kernel_parameters)\n",
    "        \n",
    "        # IRLS\n",
    "        WKRR = WeightedKernelRidgeRegression(\n",
    "            lambd=self.lambd,\n",
    "            kernel=self.kernel_name,\n",
    "            **self.kernel_parameters\n",
    "        )\n",
    "        # Initialize\n",
    "        alpha = np.zeros_like(self.y_train)\n",
    "        # Iterate until convergence or max iterations\n",
    "        for n_iter in range(max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "           # print(sigmoid(f) )\n",
    "            z = f + y / sigmoid(-y*f)\n",
    "            alpha = WKRR.fit(K, z, sample_weights=w).alpha\n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < tol:\n",
    "                break\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        return self\n",
    "            \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)    \n",
    "        return sigmoid(K_x.dot(self.alpha))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        decisions = self.decision_function(X)\n",
    "        #print(decisions)\n",
    "        predicted_classes = np.where(decisions < 0.5, -1, 1)\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KernelLogisticRegression(lambd=0.0001, kernel='polynomial', sigma=10, degree=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KernelLogisticRegression at 0x7f28bfef1490>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_,y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy=model.predict(X_test_)\n",
    "#predy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6766666666666666"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.mean(predy==y_test_)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "\n",
    "kfc=k_fold_cross_validation(model)\n",
    "kfc.validate(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #make submission\n",
    "    #convert  y to 0 and 1 class\n",
    "    output = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]==-1: \n",
    "            pred[i]==0\n",
    "            output.append(0)\n",
    "        else:output.append(1)\n",
    "\n",
    "    output  = np.array(output)\n",
    "\n",
    "    # put the output in the form of dictionary and then data frames\n",
    "    Id = np.array([i for i in range(len(output))])\n",
    "    sub = {'Id':Id,'Bound':output}\n",
    "    submision = pd.DataFrame(sub)\n",
    "    \n",
    "    print(' ... we are Done!  ...')\n",
    "    print('')\n",
    "    submision.to_csv('ssubmission1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
